{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking Out the HyperParameters in Bag of Words\n",
    "\n",
    "Using the Bag of Words method of vectorising documents, there are several ways of manipulating how Bag of Words will interpret the words found within the document.\n",
    "\n",
    "## CountVectorizer & TF-IDF\n",
    "The options that can be found are:\n",
    "\n",
    "- Stop Words\n",
    "- N-gram Range\n",
    "- Min-DF\n",
    "\n",
    "(Question for Self: Why have I short-listed these?)\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Using Naive-Bayes Classifier\n",
    "Calculating the F1 Score of Each Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '../data/hateval2019_en_train_clean.csv'\n",
    "testPath = '../data/hateval2019_en_test_clean.csv'\n",
    "\n",
    "trainSet = pd.read_csv(trainPath)\n",
    "testSet = pd.read_csv(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = trainSet.text\n",
    "trainHate = trainSet.HS\n",
    "trainTarget = trainSet.TR\n",
    "trainAggressive = trainSet.AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeSetUp(clf):\n",
    "    pipe = Pipeline(steps=[('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPipe(training_text, training_score, parameters, pipe):\n",
    "    if __name__ == \"__main__\":\n",
    "        grid_pipeline = GridSearchCV(pipe,parameters,n_jobs=4,verbose=1, scoring='f1')\n",
    "\n",
    "        print(\"Performing grid search...\")\n",
    "        print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "        print(\"parameters:\")\n",
    "        pprint(parameters)\n",
    "        t0 = time()\n",
    "        grid_pipeline.fit(training_text, training_score)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print(\"scoring paramater: f1\")\n",
    "\n",
    "        print(\"Best score: %0.3f\" % grid_pipeline.best_score_)\n",
    "        F1 = grid_pipeline.best_score_\n",
    "        print(\"Best parameters set:\")\n",
    "        best_parameters = grid_pipeline.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        return F1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 30.163s\n",
      "scoring paramater: f1\n",
      "Best score: 0.654\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   27.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.306s\n",
      "scoring paramater: f1\n",
      "Best score: 0.312\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.141s\n",
      "scoring paramater: f1\n",
      "Best score: 0.236\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.400\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(MultinomialNB())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   27.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.162s\n",
      "scoring paramater: f1\n",
      "Best score: 0.680\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.002s\n",
      "scoring paramater: f1\n",
      "Best score: 0.558\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 28.855s\n",
      "scoring paramater: f1\n",
      "Best score: 0.386\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.541\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(BernoulliNB())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__max_iter': (10000, 100000),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=4)]: Done 9600 out of 9600 | elapsed: 15.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 916.191s\n",
      "scoring paramater: f1\n",
      "Best score: 0.689\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__max_iter: 10000\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.9\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__max_iter': (10000, 100000),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=4)]: Done 9600 out of 9600 | elapsed: 14.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 877.191s\n",
      "scoring paramater: f1\n",
      "Best score: 0.535\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__max_iter: 10000\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.9\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__max_iter': (10000, 100000),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 1920 candidates, totalling 9600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=4)]: Done 9600 out of 9600 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 862.100s\n",
      "scoring paramater: f1\n",
      "Best score: 0.396\n",
      "Best parameters set:\n",
      "\tclf__alpha: 2e-05\n",
      "\tclf__max_iter: 10000\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.540\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(SGDClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "    'clf__max_iter': (10000,100000,),\n",
    "    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_iter': (10000, 100000),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 82.090s\n",
      "scoring paramater: f1\n",
      "Best score: 0.683\n",
      "Best parameters set:\n",
      "\tclf__max_iter: 10000\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_iter': (10000, 100000),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 83.734s\n",
      "scoring paramater: f1\n",
      "Best score: 0.299\n",
      "Best parameters set:\n",
      "\tclf__max_iter: 10000\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_iter': (10000, 100000),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_params() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 141, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 53, in _set_params\n    super().set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 243, in set_params\n    valid_params = self.get_params(deep=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 130, in get_params\n    return self._get_params('steps', deep=deep)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 35, in _get_params\n    for key, value in estimator.get_params(deep=True).items():\nTypeError: get_params() missing 1 required positional argument: 'self'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9ca717619c02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Getting Target Score...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtarget_F1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunPipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0moverall_F1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhate_F1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtarget_F1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maggressive_F1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-44d54335c68c>\u001b[0m in \u001b[0;36mrunPipe\u001b[1;34m(training_text, training_score, parameters, pipe)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mgrid_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done in %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"scoring paramater: f1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_params() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(LogisticRegression())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "    'clf__max_iter': (10000 ,100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "pipe = pipeSetUp(GradientBoostingClassifier)\n",
    "\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeSetUp(GradientBoostingClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#    'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "    'clf__n_estimators':(100, 1000),\n",
    "    'clf__learning_rate':(0.5, 1.0 , 1.5),\n",
    "    'clf__max_depth':(0, 1),\n",
    "    'clf__random_state':(0, 1)\n",
    "}\n",
    "\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), min_df=4, max_df=0.75)\n",
    "# do comparison with one where you don't filter out HS\n",
    "target_train_set = trainSet\n",
    "target_test_set = testSet\n",
    "\n",
    "x_train_dtm = vect.fit_transform(target_train_set.text)\n",
    "x_test_dtm = vect.transform(target_test_set.text)\n",
    "\n",
    "#bernoulli_nb = BernoulliNB()\n",
    "lr = LogisticRegression(max_iter=100000)\n",
    "\n",
    "#bernoulli_nb.fit(x_train_dtm, target_train_set.AG)\n",
    "\n",
    "#y_pred_class_bernoulli_nb = bernoulli_nb.predict(x_test_dtm)\n",
    "y_pred_class_lr = lr.predict(x_test_dtm)\n",
    "\n",
    "#bernoulli_nb_acc = metrics.accuracy_score(target_test_set.AG, y_pred_class_bernoulli_nb)\n",
    "#bernoulli_nb_acc\n",
    "\n",
    "print(\"Aggressive Score\")\n",
    "#print(classification_report(target_test_set.AG, y_pred_class_bernoulli_nb, labels=[0,1]))\n",
    "print(classification_report(target_test_set.AG, y_pred_class_lr, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), min_df=4, max_df=0.75)\n",
    "# do comparison with one where you don't filter out HS\n",
    "target_train_set = trainSet[(trainSet[\"HS\"]==1)]\n",
    "target_test_set = testSet[(testSet[\"HS\"]==1)]\n",
    "\n",
    "x_train_dtm = vect.fit_transform(target_train_set.text)\n",
    "x_test_dtm = vect.transform(target_test_set.text)\n",
    "\n",
    "# grid pipeline is missing these variables which is one of the reasons why the F1-score i slow\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.5,max_depth=2, random_state=0)\n",
    "\n",
    "gb.fit(x_train_dtm, target_train_set.TR)\n",
    "\n",
    "y_pred_class_gb = gb.predict(x_test_dtm)\n",
    "\n",
    "gb_acc = metrics.accuracy_score(target_test_set.TR, y_pred_class_gb)\n",
    "gb_acc\n",
    "\n",
    "print(\"Target Score\")\n",
    "print(classification_report(target_test_set.TR, y_pred_class_gb, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Score\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.84      0.89       731\n",
    "           1       0.81      0.93      0.87       529\n",
    "\n",
    "    accuracy                           0.88      1260\n",
    "   macro avg       0.88      0.89      0.88      1260\n",
    "weighted avg       0.89      0.88      0.88      1260\n",
    "\n",
    "Target Score\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.91      0.88       731\n",
    "           1       0.86      0.80      0.83       529\n",
    "\n",
    "    accuracy                           0.86      1260\n",
    "   macro avg       0.86      0.85      0.86      1260\n",
    "weighted avg       0.86      0.86      0.86      1260\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test_set[(y_pred_class_gb==1) & (target_test_set.TR==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall F1 Scores\n",
    "\n",
    "F1 = (F1(HS) + F1(AR) + F1(TR))/3\n",
    "\n",
    "MultinomialNB Score: 0.400\n",
    "\n",
    "BernoulliNB Score: 0.541\n",
    "\n",
    "Logistic Regression: 0.489\n",
    "\n",
    "SGDClassifier Score: 0.539\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
