{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking Out the Best Classification Model for the Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '../data/hateval2019_en_train_clean.csv'\n",
    "testPath = '../data/hateval2019_en_test_clean.csv'\n",
    "\n",
    "trainSet = pd.read_csv(trainPath)\n",
    "testSet = pd.read_csv(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = trainSet.text\n",
    "trainHate = trainSet.HS\n",
    "trainTarget = trainSet.TR\n",
    "trainAggressive = trainSet.AG\n",
    "\n",
    "testText = testSet.text\n",
    "testHate = testSet.HS\n",
    "testTarget = testSet.TR\n",
    "testAggressive = testSet.AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Previous Experiments these are the settings that are currently the most suitable for a general experiment\n",
    "#vect = CountVectorizer(stop_words='english', ngram_range=(1, 1), min_df=4, max_df=0.5)\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), min_df=4, max_df=0.5)\n",
    "\n",
    "x_train_dtm = vect.fit_transform(trainText)\n",
    "x_test_dtm = vect.transform(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifying(x, y):\n",
    "    lr = LogisticRegression(max_iter=10000)\n",
    "    sgd = SGDClassifier()\n",
    "    multi_nb = MultinomialNB()\n",
    "    gaussian_nb = GaussianNB()\n",
    "    bernoulli_nb = BernoulliNB()\n",
    "    svm = SVC()\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "\n",
    "    %time multi_nb.fit(x, y)\n",
    "    %time bernoulli_nb.fit(x, y)\n",
    "    %time gaussian_nb.fit(x.toarray(), y)\n",
    "    %time lr.fit(x, y)\n",
    "    %time sgd.fit(x, y)\n",
    "    %time svm.fit(x, y)\n",
    "    %time rf.fit(x, y)\n",
    "    %time gb.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(x, y):\n",
    "    #Naive Bayes\n",
    "    y_pred_class_multi_nb = multi_nb.predict(x)\n",
    "    y_pred_class_bernoulli_nb = bernoulli_nb.predict(x)\n",
    "    y_pred_class_gaussian_nb = gaussian_nb.predict(x.toarray())\n",
    "\n",
    "    multi_nb_acc = metrics.accuracy_score(y, y_pred_class_multi_nb)\n",
    "    bernoulli_nb_acc = metrics.accuracy_score(y, y_pred_class_bernoulli_nb)\n",
    "    gaussian_nb_acc = metrics.accuracy_score(y, y_pred_class_gaussian_nb)\n",
    "\n",
    "    #Linear Models\n",
    "    y_pred_class_lr = lr.predict(x)\n",
    "    y_pred_class_sgd = sgd.predict(x)\n",
    "\n",
    "    lr_acc = metrics.accuracy_score(y, y_pred_class_lr)\n",
    "    sgd_acc = metrics.accuracy_score(y, y_pred_class_sgd)\n",
    "\n",
    "\n",
    "    #Support Vector Machine\n",
    "    y_pred_class_svm = svm.predict(x)\n",
    "\n",
    "    svm_acc = metrics.accuracy_score(y, y_pred_class_svm)\n",
    "\n",
    "    #Ensemble\n",
    "    y_pred_class_rf = rf.predict(x)\n",
    "    y_pred_class_gb = gb.predict(x)\n",
    "\n",
    "    rf_acc = metrics.accuracy_score(y, y_pred_class_rf)\n",
    "    gb_acc = metrics.accuracy_score(y, y_pred_class_gb)\n",
    "    \n",
    "    return [multi_nb_acc, bernoulli_nb_acc, gaussian_nb_acc, lr_acc, sgd_acc, svm_acc, rf_acc, gb_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.97 ms\n",
      "Wall time: 4 ms\n",
      "Wall time: 660 ms\n",
      "Wall time: 83 ms\n",
      "Wall time: 18 ms\n",
      "Wall time: 6.87 s\n",
      "Wall time: 4.44 s\n",
      "Wall time: 776 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'multi_nb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-276a96b1a235>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Hate Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifying\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_dtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainHate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0maccuracy_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_dtm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestHate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-6ed9146b208e>\u001b[0m in \u001b[0;36mpredicting\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredicting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#Naive Bayes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my_pred_class_multi_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my_pred_class_bernoulli_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbernoulli_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred_class_gaussian_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'multi_nb' is not defined"
     ]
    }
   ],
   "source": [
    "classifiers = ['Multinomial NB', 'Bernoulli NB', 'Gaussian NB', 'Logistic Regression ', 'Stochastic Gradient Descent', 'Support Vector Machine', 'Random Forest', 'Gradient Boosting']\n",
    "\n",
    "#Hate Score\n",
    "classifying(x_train_dtm, trainHate)\n",
    "accuracy_array = predicting(x_test_dtm, testHate)\n",
    "\n",
    "data = pd.DataFrame(accuracy_array, columns=['Accuracy'], index=classifiers)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Score\n",
    "classifying(x_train_dtm, trainTarget)\n",
    "accuracy_array = predicting(x_test_dtm, testTarget)\n",
    "\n",
    "data = pd.DataFrame(accuracy_array, columns=['Accuracy'], index=classifiers)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggressive Score\n",
    "classifying(x_train_dtm, trainAggressive)\n",
    "accuracy_array = predicting(x_test_dtm, testAggressive)\n",
    "\n",
    "data = pd.DataFrame(accuracy_array, columns=['Accuracy'], index=classifiers)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Hate Score\n",
    "```\n",
    "Accuracy\n",
    "Multinomial NB \t         0.461333\n",
    "Bernoulli NB \t           0.490667\n",
    "Gaussian NB \t            0.459667\n",
    "Logistic Regression \t    0.493000\n",
    "Stochastic Gradient Descent 0.494667\n",
    "Support Vector Machine      0.459000\n",
    "Random Forest \t          0.453667\n",
    "Gradient Boosting           0.452667\n",
    "```\n",
    "\n",
    "## Target Score\n",
    "```\n",
    "Multinomial NB \t             0.722333\n",
    "Bernoulli NB \t               0.795667\n",
    "Gaussian NB \t                0.736667\n",
    "Logistic Regression \t        0.785667\n",
    "Stochastic Gradient Descent \t0.766000\n",
    "Support Vector Machine \t     0.722333\n",
    "Random Forest \t              0.739667\n",
    "Gradient Boosting \t          0.832000\n",
    "```\n",
    "\n",
    "## Aggressive Score\n",
    "```\n",
    "Multinomial NB \t             0.640333\n",
    "Bernoulli NB \t               0.702667\n",
    "Gaussian NB \t                0.580000\n",
    "Logistic Regression \t        0.685000\n",
    "Stochastic Gradient Descent \t0.665000\n",
    "Support Vector Machine \t     0.693000\n",
    "Random Forest \t              0.668333\n",
    "Gradient Boosting \t          0.655667\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
