{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picking Out the HyperParameters in Bag of Words\n",
    "\n",
    "Using the Bag of Words method of vectorising documents, there are several ways of manipulating how Bag of Words will interpret the words found within the document.\n",
    "\n",
    "## CountVectorizer & TF-IDF\n",
    "The options that can be found are:\n",
    "\n",
    "- Stop Words\n",
    "- N-gram Range\n",
    "- Min-DF\n",
    "\n",
    "(Question for Self: Why have I short-listed these?)\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Using Naive-Bayes Classifier\n",
    "Calculating the F1 Score of Each Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '../data/hateval2019_en_train_clean.csv'\n",
    "testPath = '../data/hateval2019_en_test_clean.csv'\n",
    "\n",
    "trainSet = pd.read_csv(trainPath)\n",
    "testSet = pd.read_csv(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainText = trainSet.text\n",
    "trainHate = trainSet.HS\n",
    "trainTarget = trainSet.TR\n",
    "trainAggressive = trainSet.AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeSetUp(clf):\n",
    "    pipe = Pipeline(steps=[('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', clf)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPipe(training_text, training_score, parameters, pipe):\n",
    "    if __name__ == \"__main__\":\n",
    "        grid_pipeline = GridSearchCV(pipe,parameters,n_jobs=4,verbose=1, scoring='f1')\n",
    "\n",
    "        print(\"Performing grid search...\")\n",
    "        print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "        print(\"parameters:\")\n",
    "        pprint(parameters)\n",
    "        t0 = time()\n",
    "        grid_pipeline.fit(training_text, training_score)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print(\"scoring paramater: f1\")\n",
    "\n",
    "        print(\"Best score: %0.3f\" % grid_pipeline.best_score_)\n",
    "        F1 = grid_pipeline.best_score_\n",
    "        print(\"Best parameters set:\")\n",
    "        best_parameters = grid_pipeline.best_estimator_.get_params()\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        return F1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   36.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 36.685s\n",
      "scoring paramater: f1\n",
      "Best score: 0.654\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   36.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.253s\n",
      "scoring paramater: f1\n",
      "Best score: 0.312\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 35.660s\n",
      "scoring paramater: f1\n",
      "Best score: 0.236\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.400\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(MultinomialNB())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#     'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   34.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 34.390s\n",
      "scoring paramater: f1\n",
      "Best score: 0.680\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 35.278s\n",
      "scoring paramater: f1\n",
      "Best score: 0.558\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 39.182s\n",
      "scoring paramater: f1\n",
      "Best score: 0.386\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.541\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(BernoulliNB())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#     'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=4)]: Done 4800 out of 4800 | elapsed:  8.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 516.359s\n",
      "scoring paramater: f1\n",
      "Best score: 0.688\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 1.0\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 4800 out of 4800 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 490.511s\n",
      "scoring paramater: f1\n",
      "Best score: 0.533\n",
      "Best parameters set:\n",
      "\tclf__alpha: 2e-05\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.9\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done 4800 out of 4800 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 482.550s\n",
      "scoring paramater: f1\n",
      "Best score: 0.396\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.9\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.539\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(SGDClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#     'clf__max_iter': (100000,),\n",
    "    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Hate Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__max_iter': (100000,),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   53.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 54.093s\n",
      "scoring paramater: f1\n",
      "Best score: 0.683\n",
      "Best parameters set:\n",
      "\tclf__max_iter: 100000\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__max_iter': (100000,),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   51.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 52.644s\n",
      "scoring paramater: f1\n",
      "Best score: 0.485\n",
      "Best parameters set:\n",
      "\tclf__max_iter: 100000\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 2\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Getting Aggressive Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: MultinomialNB\n",
      "parameters:\n",
      "{'clf__max_iter': (100000,),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   51.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 52.550s\n",
      "scoring paramater: f1\n",
      "Best score: 0.299\n",
      "Best parameters set:\n",
      "\tclf__max_iter: 100000\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n",
      "Overall F1 Score : 0.489\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(LogisticRegression())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "    'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "print('Getting Hate Score...')\n",
    "hate_F1 = runPipe(trainText, trainHate, parameters, pipe)\n",
    "print('Getting Aggressive Score...')\n",
    "aggressive_F1 = runPipe(trainText, trainAggressive, parameters, pipe)\n",
    "\n",
    "pipe = pipeSetUp(GradientBoostingClassifier)\n",
    "\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "\n",
    "overall_F1 = (hate_F1 + target_F1 + aggressive_F1)/3\n",
    "\n",
    "print(\"Overall F1 Score : %0.3f\" % (overall_F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Target Score...\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__learning_rate': (0, 0.5, 1.0, 1.5, 2.0),\n",
      " 'clf__max_depth': (0, 1, 2),\n",
      " 'clf__n_estimators': (0, 100, 1000),\n",
      " 'clf__random_state': (0, 1),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 7200 candidates, totalling 36000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   34.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 3192 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=4)]: Done 4042 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 4992 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done 6042 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=4)]: Done 7192 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=4)]: Done 8442 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=4)]: Done 9792 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=4)]: Done 11242 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=4)]: Done 12792 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=4)]: Done 14442 tasks      | elapsed: 66.4min\n",
      "[Parallel(n_jobs=4)]: Done 16192 tasks      | elapsed: 68.5min\n",
      "[Parallel(n_jobs=4)]: Done 18042 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=4)]: Done 19992 tasks      | elapsed: 91.2min\n",
      "[Parallel(n_jobs=4)]: Done 22042 tasks      | elapsed: 125.1min\n",
      "[Parallel(n_jobs=4)]: Done 24192 tasks      | elapsed: 127.5min\n",
      "[Parallel(n_jobs=4)]: Done 26442 tasks      | elapsed: 149.6min\n",
      "[Parallel(n_jobs=4)]: Done 28792 tasks      | elapsed: 183.7min\n",
      "[Parallel(n_jobs=4)]: Done 31242 tasks      | elapsed: 186.7min\n",
      "[Parallel(n_jobs=4)]: Done 33792 tasks      | elapsed: 207.0min\n",
      "[Parallel(n_jobs=4)]: Done 36000 out of 36000 | elapsed: 239.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 14352.091s\n",
      "scoring paramater: f1\n",
      "Best score: 0.573\n",
      "Best parameters set:\n",
      "\tclf__learning_rate: 1.5\n",
      "\tclf__max_depth: 2\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__random_state: 0\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeSetUp(GradientBoostingClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#    'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "#    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "    'clf__n_estimators':(0, 100, 1000),\n",
    "    'clf__learning_rate':(0, 0.5, 1.0 , 1.5, 2.0),\n",
    "    'clf__max_depth':(0, 1, 2),\n",
    "    'clf__random_state':(0, 1)\n",
    "}\n",
    "\n",
    "print('Getting Target Score...')\n",
    "target_F1 = runPipe(trainText, trainTarget, parameters, pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggressive Score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.81      0.68       666\n",
      "           1       0.64      0.37      0.47       594\n",
      "\n",
      "    accuracy                           0.60      1260\n",
      "   macro avg       0.61      0.59      0.57      1260\n",
      "weighted avg       0.61      0.60      0.58      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2, max_df=0.75)\n",
    "# do comparison with one where you don't filter out HS\n",
    "target_train_set = trainSet[(trainSet[\"HS\"]==1)]\n",
    "target_test_set = testSet[(testSet[\"HS\"]==1)]\n",
    "\n",
    "x_train_dtm = vect.fit_transform(target_train_set.text)\n",
    "x_test_dtm = vect.transform(target_test_set.text)\n",
    "\n",
    "bernoulli_nb = BernoulliNB()\n",
    "\n",
    "bernoulli_nb.fit(x_train_dtm, target_train_set.AG)\n",
    "\n",
    "y_pred_class_bernoulli_nb = bernoulli_nb.predict(x_test_dtm)\n",
    "\n",
    "bernoulli_nb_acc = metrics.accuracy_score(target_test_set.AG, y_pred_class_bernoulli_nb)\n",
    "bernoulli_nb_acc\n",
    "\n",
    "print(\"Aggressive Score\")\n",
    "print(classification_report(target_test_set.AG, y_pred_class_bernoulli_nb, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       731\n",
      "           1       0.86      0.80      0.83       529\n",
      "\n",
      "    accuracy                           0.86      1260\n",
      "   macro avg       0.86      0.85      0.86      1260\n",
      "weighted avg       0.86      0.86      0.86      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2), min_df=4, max_df=0.75)\n",
    "# do comparison with one where you don't filter out HS\n",
    "target_train_set = trainSet[(trainSet[\"HS\"]==1)]\n",
    "target_test_set = testSet[(testSet[\"HS\"]==1)]\n",
    "\n",
    "x_train_dtm = vect.fit_transform(target_train_set.text)\n",
    "x_test_dtm = vect.transform(target_test_set.text)\n",
    "\n",
    "# grid pipeline is missing these variables which is one of the reasons why the F1-score i slow\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.5,max_depth=2, random_state=0)\n",
    "\n",
    "gb.fit(x_train_dtm, target_train_set.TR)\n",
    "\n",
    "y_pred_class_gb = gb.predict(x_test_dtm)\n",
    "\n",
    "gb_acc = metrics.accuracy_score(target_test_set.TR, y_pred_class_gb)\n",
    "gb_acc\n",
    "\n",
    "print(\"Target Score\")\n",
    "print(classification_report(target_test_set.TR, y_pred_class_gb, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Score\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.94      0.84      0.89       731\n",
    "           1       0.81      0.93      0.87       529\n",
    "\n",
    "    accuracy                           0.88      1260\n",
    "   macro avg       0.88      0.89      0.88      1260\n",
    "weighted avg       0.89      0.88      0.88      1260\n",
    "\n",
    "Target Score\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.91      0.88       731\n",
    "           1       0.86      0.80      0.83       529\n",
    "\n",
    "    accuracy                           0.86      1260\n",
    "   macro avg       0.86      0.85      0.86      1260\n",
    "weighted avg       0.86      0.86      0.86      1260\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>2381</td>\n",
       "      <td>30806</td>\n",
       "      <td>I can never get mad over a bitch cause i know ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>2384</td>\n",
       "      <td>33611</td>\n",
       "      <td>I #want meüôå and I will do anything to #keep me...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2387</td>\n",
       "      <td>30408</td>\n",
       "      <td>I like my niggas meanüòçüòçüòç If a bitch touch you ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2394</td>\n",
       "      <td>31203</td>\n",
       "      <td>Bitches be selling they body and acting boogie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>33069</td>\n",
       "      <td>Bitch I'm the man. Hoe I'm the man. You know I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>2424</td>\n",
       "      <td>31211</td>\n",
       "      <td>swear, next bitch i fuck ima get her pregnant ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>2435</td>\n",
       "      <td>32291</td>\n",
       "      <td>3) \"you okay?\" \"Fuck you you fat bitch.\" \"Fuck...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>2441</td>\n",
       "      <td>33807</td>\n",
       "      <td>You won't catch me on this hoe arguing with a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2447</td>\n",
       "      <td>31109</td>\n",
       "      <td>A nigga never go respect a bitch who post noth...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>2451</td>\n",
       "      <td>33718</td>\n",
       "      <td>When you're just tryna be happy, but then a bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>30522</td>\n",
       "      <td>Every man Cheat and Every bitch lie. Call it E...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>2504</td>\n",
       "      <td>31061</td>\n",
       "      <td>I literally HATE drunk me. Bitch is a lil cunt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2512</td>\n",
       "      <td>32645</td>\n",
       "      <td>@USER KARMA IS A BITCH! JUST SIT AND WAIT FOR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>2513</td>\n",
       "      <td>30194</td>\n",
       "      <td>Bitches kill me with that bitch wanna be me ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>2516</td>\n",
       "      <td>32527</td>\n",
       "      <td>The next hoe that you love I bet I'll make tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>2518</td>\n",
       "      <td>32920</td>\n",
       "      <td>Shoes? $1,200!  Glasses? Like $400.  But bitch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>2545</td>\n",
       "      <td>32017</td>\n",
       "      <td>Bitches hollering it's tooo hot!! Well bitch g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>2554</td>\n",
       "      <td>31610</td>\n",
       "      <td>and no ian gon do fw yo clique but the next ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2579</td>\n",
       "      <td>32298</td>\n",
       "      <td>OMM ILL BEAT A BITCH FUCK YOU PLAY ME FOR HOE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>2587</td>\n",
       "      <td>30081</td>\n",
       "      <td>I'm tired of bitches wearin no clothes then go...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>2620</td>\n",
       "      <td>32742</td>\n",
       "      <td>bitch ass hoe you feel me</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>2623</td>\n",
       "      <td>31390</td>\n",
       "      <td>Bitches Boyfriends/baby daddy/ husband be lock...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2653</td>\n",
       "      <td>30811</td>\n",
       "      <td>Chicks be 2 weeks pregnant and be like \"what m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2657</td>\n",
       "      <td>33044</td>\n",
       "      <td>Ion care what a bitch think or how a hoe feel ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>2670</td>\n",
       "      <td>33604</td>\n",
       "      <td>bitches be expecting you to stay around while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>2680</td>\n",
       "      <td>31979</td>\n",
       "      <td>I hate for females who hang with me but out he...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>2681</td>\n",
       "      <td>30599</td>\n",
       "      <td>Morning.  Twitter is being anal and trying to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>2696</td>\n",
       "      <td>33656</td>\n",
       "      <td>Bitches get mad cuz they don‚Äôt get posted...Bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>2701</td>\n",
       "      <td>30142</td>\n",
       "      <td>A hoe ass bitch &amp; a bitch ass nigga only gonna...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>2704</td>\n",
       "      <td>32846</td>\n",
       "      <td>um who are you is probably the most dumb bitch...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2705</td>\n",
       "      <td>33434</td>\n",
       "      <td>bay bitch  always on the move witch  dick to d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>2724</td>\n",
       "      <td>34397</td>\n",
       "      <td>Now who tf could be jealous of any bitch that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>2741</td>\n",
       "      <td>30312</td>\n",
       "      <td>Broke niggas ain't shit cept to a broke bitch,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>2743</td>\n",
       "      <td>34134</td>\n",
       "      <td>@USER OK BITCH WELL ILL LEFT SWIPE YOU AGAIN H...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>2768</td>\n",
       "      <td>33733</td>\n",
       "      <td>When you gotta break check a little teenage bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>2805</td>\n",
       "      <td>30824</td>\n",
       "      <td>Miserable loves company ü§ó, that's why a bitch ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2829</td>\n",
       "      <td>33178</td>\n",
       "      <td>I hate when a bitch call you ugly hoe you had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>2833</td>\n",
       "      <td>33598</td>\n",
       "      <td>warning to all you dumb bitches: i don't do no...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>2838</td>\n",
       "      <td>30537</td>\n",
       "      <td>@USER @USER Im here hoe. Is someone bothering ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>2864</td>\n",
       "      <td>32154</td>\n",
       "      <td>Y'all: \"Treat me loke a nutrag when we fuck\" b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>2900</td>\n",
       "      <td>32365</td>\n",
       "      <td>I will never trust a hoe I to went outta respe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2946</td>\n",
       "      <td>33988</td>\n",
       "      <td>When u give a hoe a compliment and the bitch d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>2970</td>\n",
       "      <td>33058</td>\n",
       "      <td>bitches be on this hoe reading threads on how ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2990</td>\n",
       "      <td>32638</td>\n",
       "      <td>Every light skin bitch use this emoji \"üçØ\" when...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     id                                               text  \\\n",
       "2381        2381  30806  I can never get mad over a bitch cause i know ...   \n",
       "2384        2384  33611  I #want meüôå and I will do anything to #keep me...   \n",
       "2387        2387  30408  I like my niggas meanüòçüòçüòç If a bitch touch you ...   \n",
       "2394        2394  31203  Bitches be selling they body and acting boogie...   \n",
       "2401        2401  33069  Bitch I'm the man. Hoe I'm the man. You know I...   \n",
       "2424        2424  31211  swear, next bitch i fuck ima get her pregnant ...   \n",
       "2435        2435  32291  3) \"you okay?\" \"Fuck you you fat bitch.\" \"Fuck...   \n",
       "2441        2441  33807  You won't catch me on this hoe arguing with a ...   \n",
       "2447        2447  31109  A nigga never go respect a bitch who post noth...   \n",
       "2451        2451  33718  When you're just tryna be happy, but then a bi...   \n",
       "2496        2496  30522  Every man Cheat and Every bitch lie. Call it E...   \n",
       "2504        2504  31061     I literally HATE drunk me. Bitch is a lil cunt   \n",
       "2512        2512  32645  @USER KARMA IS A BITCH! JUST SIT AND WAIT FOR ...   \n",
       "2513        2513  30194  Bitches kill me with that bitch wanna be me ho...   \n",
       "2516        2516  32527  The next hoe that you love I bet I'll make tha...   \n",
       "2518        2518  32920  Shoes? $1,200!  Glasses? Like $400.  But bitch...   \n",
       "2545        2545  32017  Bitches hollering it's tooo hot!! Well bitch g...   \n",
       "2554        2554  31610  and no ian gon do fw yo clique but the next ho...   \n",
       "2579        2579  32298      OMM ILL BEAT A BITCH FUCK YOU PLAY ME FOR HOE   \n",
       "2587        2587  30081  I'm tired of bitches wearin no clothes then go...   \n",
       "2620        2620  32742                          bitch ass hoe you feel me   \n",
       "2623        2623  31390  Bitches Boyfriends/baby daddy/ husband be lock...   \n",
       "2653        2653  30811  Chicks be 2 weeks pregnant and be like \"what m...   \n",
       "2657        2657  33044  Ion care what a bitch think or how a hoe feel ...   \n",
       "2670        2670  33604  bitches be expecting you to stay around while ...   \n",
       "2680        2680  31979  I hate for females who hang with me but out he...   \n",
       "2681        2681  30599  Morning.  Twitter is being anal and trying to ...   \n",
       "2696        2696  33656  Bitches get mad cuz they don‚Äôt get posted...Bi...   \n",
       "2701        2701  30142  A hoe ass bitch & a bitch ass nigga only gonna...   \n",
       "2704        2704  32846  um who are you is probably the most dumb bitch...   \n",
       "2705        2705  33434  bay bitch  always on the move witch  dick to d...   \n",
       "2724        2724  34397  Now who tf could be jealous of any bitch that ...   \n",
       "2741        2741  30312  Broke niggas ain't shit cept to a broke bitch,...   \n",
       "2743        2743  34134  @USER OK BITCH WELL ILL LEFT SWIPE YOU AGAIN H...   \n",
       "2768        2768  33733  When you gotta break check a little teenage bi...   \n",
       "2805        2805  30824  Miserable loves company ü§ó, that's why a bitch ...   \n",
       "2829        2829  33178  I hate when a bitch call you ugly hoe you had ...   \n",
       "2833        2833  33598  warning to all you dumb bitches: i don't do no...   \n",
       "2838        2838  30537  @USER @USER Im here hoe. Is someone bothering ...   \n",
       "2864        2864  32154  Y'all: \"Treat me loke a nutrag when we fuck\" b...   \n",
       "2900        2900  32365  I will never trust a hoe I to went outta respe...   \n",
       "2946        2946  33988  When u give a hoe a compliment and the bitch d...   \n",
       "2970        2970  33058  bitches be on this hoe reading threads on how ...   \n",
       "2990        2990  32638  Every light skin bitch use this emoji \"üçØ\" when...   \n",
       "\n",
       "      HS  TR  AG  \n",
       "2381   1   0   0  \n",
       "2384   1   0   1  \n",
       "2387   1   0   1  \n",
       "2394   1   0   1  \n",
       "2401   1   0   1  \n",
       "2424   1   0   1  \n",
       "2435   1   0   0  \n",
       "2441   1   0   0  \n",
       "2447   1   0   1  \n",
       "2451   1   0   0  \n",
       "2496   1   0   0  \n",
       "2504   1   0   0  \n",
       "2512   1   0   0  \n",
       "2513   1   0   0  \n",
       "2516   1   0   1  \n",
       "2518   1   0   0  \n",
       "2545   1   0   0  \n",
       "2554   1   0   1  \n",
       "2579   1   0   1  \n",
       "2587   1   0   0  \n",
       "2620   1   0   0  \n",
       "2623   1   0   0  \n",
       "2653   1   0   0  \n",
       "2657   1   0   1  \n",
       "2670   1   0   1  \n",
       "2680   1   0   0  \n",
       "2681   1   0   1  \n",
       "2696   1   0   0  \n",
       "2701   1   0   0  \n",
       "2704   1   0   0  \n",
       "2705   1   0   0  \n",
       "2724   1   0   0  \n",
       "2741   1   0   0  \n",
       "2743   1   0   0  \n",
       "2768   1   0   0  \n",
       "2805   1   0   1  \n",
       "2829   1   0   0  \n",
       "2833   1   0   0  \n",
       "2838   1   0   1  \n",
       "2864   1   0   0  \n",
       "2900   1   0   0  \n",
       "2946   1   0   0  \n",
       "2970   1   0   0  \n",
       "2990   1   0   0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_set[(y_pred_class_gb==1) & (target_test_set.TR==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall F1 Scores\n",
    "\n",
    "F1 = (F1(HS) + F1(AR) + F1(TR))/3\n",
    "\n",
    "MultinomialNB Score: 0.400\n",
    "\n",
    "BernoulliNB Score: 0.541\n",
    "\n",
    "Logistic Regression: 0.489\n",
    "\n",
    "SGDClassifier Score: 0.539\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
