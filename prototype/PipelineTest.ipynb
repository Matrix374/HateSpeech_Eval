{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Prototype\n",
    "\n",
    "MultinomialNB = 0.768\n",
    "SGDClassifier = 0.781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6750,)\n",
      "(2250,)\n",
      "(6750,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "testPath = '../data/hateval2019_en_test_clean.csv'\n",
    "trainPath = '../data/hateval2019_en_train_clean.csv'\n",
    "\n",
    "testSet = pd.read_csv(testPath)\n",
    "trainSet = pd.read_csv(trainPath)\n",
    "\n",
    "x = trainSet.text\n",
    "y = trainSet.HS\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: SGDClassifier()\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75, 1.0, 0.9), 'vect__stop_words': ('english',), 'vect__min_df': (2, 0.1, 3, 0.2, 4), 'vect__ngram_range': ((1, 1), (1, 2)), 'tfidf__use_idf': (True, False)}\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:   32.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 32.882s\n",
      "\n",
      "Best score: 0.768\n",
      "Best parameters set:\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__min_df: 4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#     'clf__max_iter': (100000,),\n",
    "#    'clf__penalty': ('l2', 'elasticnet'),\n",
    "#    'clf__max_iter': (10, 100, 500, 1000),\n",
    "#     'clf__early_stopping': (True,False),\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_pipeline = GridSearchCV(pipe,parameters,n_jobs=4,verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "    print(\"classifier: SGDClassifier()\")\n",
    "    print(\"parameters:\")\n",
    "    print(parameters)\n",
    "    t0 = time()\n",
    "    grid_pipeline.fit(x_train,y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_pipeline.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_pipeline.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
